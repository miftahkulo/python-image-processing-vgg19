# -*- coding: utf-8 -*-
"""Copy of Fish Classification VGG19.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xgj7O1tY2g4vYtA8-8KdY96csHSSvcfj
"""

from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout, Layer, InputSpec, Conv2D, MaxPooling2D, Activation, BatchNormalization
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.applications.vgg19 import preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from keras.utils.vis_utils import plot_model
import numpy as np
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt
from glob import glob
from tqdm import tqdm

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/Shareddrives/FishClassification/

"""#IMAGE ANALYZING"""

# define global variable
IMAGE_DIR = "images2/"

"""# 1. Image Information Analysis"""

x_data = [] 
y_data = []
list_width, list_height = [],[]

for category in glob(IMAGE_DIR+'/*'):
    for file in tqdm(glob(category+'/*.jpg')):
        img_array=cv2.imread(file)
        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)
        x_data.append(img_array) 
        y_data.append(category.split("/")[-1])
        h, w, _ = img_array.shape
        list_width.append(w)
        list_height.append(h)
        
data=pd.DataFrame({'image': x_data,'label': y_data})

"""##deleting not jpg file"""

#checking jpg file
for category in glob(IMAGE_DIR+'/*'):
    for file in tqdm(glob(category+'/*.png')):
        img_array=cv2.imread(file)
        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)

#remove png file
for category in glob(IMAGE_DIR+'/*'):
    for file in glob(category+'/*.png'):
        os.remove(file)

#rechecking jfif file
for category in glob(IMAGE_DIR+'/*'):
    for file in tqdm(glob(category+'/*.png')):
        img_array=cv2.imread(file)
        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)

"""## check shape & dimension"""

data.shape

from collections import Counter
Counter(y_data)

# overview dimension of images
fig, ax = plt.subplots(1, 2, figsize = (20, 5))

ax[0].plot(np.arange(1, len(list_width) + 1), list_width)
ax[0].set_title("Width Image Distribution")
ax[0].grid(True)

ax[1].plot(np.arange(1, len(list_height) + 1), list_height)
ax[1].set_title("Height Image Distribution")
ax[1].grid(True)

plt.show()

colors = ['#FF0000','#00FF00','#0000FF']
plt.pie(data.label.value_counts(),startangle=90,explode=[0.05,0.05,0.05],autopct='%0.2f%%',
        labels=['Pseudanthias Randalli', 'Pseudanthias Lori', 'Pseudanthias Smithvanizi'], colors= colors,radius=3)
plt.show()

plt.figure(figsize=(20,15))
for i in range(9):
    plt.subplot(4,3,(i%12)+1)
    index=np.random.randint(474)
    plt.title('Jenis Ikan {0}'.format(data.label[index]),fontdict={'size':20,'weight':'bold'})
    plt.imshow(data.image[index])
    plt.tight_layout()

className = glob(IMAGE_DIR + '/*' )
numberOfClass = len(className)
print("Number Of Class: ",numberOfClass)

"""#Splitting Image"""

import shutil
import argparse
import random

root_dir = IMAGE_DIR
classes_dir = ['pseudanthias_lori', 'pseudanthias_randalli','pseudanthias_smithvanizi']

train_ratio = 0.85
val_ratio = 0.10

for cls in classes_dir:
    os.makedirs(root_dir +'train/' + cls, exist_ok=True)
    os.makedirs(root_dir +'test/' + cls, exist_ok=True)
    os.makedirs(root_dir +'val/' + cls, exist_ok=True)
    
    # for each class, let's counts its elements
    src = root_dir + cls
    allFileNames = os.listdir(src)

    # shuffle it and split into train/test/va
    np.random.shuffle(allFileNames)
    train_FileNames, test_FileNames, val_FileNames = np.split(np.array(allFileNames),[int(train_ratio * len(allFileNames)), int((1-val_ratio) * len(allFileNames))])
    
    # save their initial path
    train_FileNames = [src+'/'+ name  for name in train_FileNames.tolist()]
    test_FileNames  = [src+'/' + name for name in test_FileNames.tolist()]
    val_FileNames   = [src+'/' + name for name in val_FileNames.tolist()]
    print("\n *****************************",
          "\n Total images: ",cls, len(allFileNames),
          '\n Training: ', len(train_FileNames),
          '\n Testing: ', len(test_FileNames),
          '\n Validation: ', len(val_FileNames),
          '\n *****************************')
        # copy files from the initial path to the final folders
    for name in train_FileNames:
      shutil.copy(name, root_dir +'train/' + cls)
    for name in test_FileNames:
      shutil.copy(name, root_dir +'test/' + cls)
    for name in val_FileNames:
      shutil.copy(name, root_dir +'val/' + cls)

# checking
paths = ['train/', 'test/','val/']
for p in paths:
  for dir,subdir,files in os.walk(root_dir + p):
    print(dir,' ', p, str(len(files)))

"""#Create Model"""

vgg = VGG19(input_shape=(224,224,3), weights='imagenet', pooling="max", include_top=False)
#do not train the pre-trained layers of VGG-19
for layer in vgg.layers:
    layer.trainable = False

x = Flatten()(vgg.output)
x = Dense(64, activation='relu', name='FC_1')(x)
x = BatchNormalization()(x)
x = Dropout(0.3)(x)

#adding output layer.Softmax classifier is used as it is multi-class classification
prediction = Dense(3, activation='softmax')(x)

model = Model(inputs=vgg.input, outputs=prediction)

model.compile(loss = "sparse_categorical_crossentropy",
              optimizer = "adam",
              metrics = ["accuracy"])

batch_size = 256

plot_model(model)

# view the structure of the model
model.summary()

train_path = "images2/train/"
test_path = "images2/test/"
val_path = "images2/val/"

#RESIZING IMAGE

x_train=[]

for folder in os.listdir(train_path):

    sub_path=train_path+folder

    for img in os.listdir(sub_path):

        image_path=sub_path+"/"+img

        ext = os.path.splitext(image_path)[-1].lower()

        if(ext == ".jpg" or ext == ".jpeg"):

            img_arr=cv2.imread(image_path)

            img_arr=cv2.resize(img_arr,(224,224))

            x_train.append(img_arr)

x_test=[]

for folder in os.listdir(test_path):

    sub_path=test_path+folder

    for img in os.listdir(sub_path):

        image_path=sub_path+"/"+img

        ext = os.path.splitext(image_path)[-1].lower()

        if(ext == ".jpg" or ext == ".jpeg"):

            img_arr=cv2.imread(image_path)

            img_arr=cv2.resize(img_arr,(224,224))

            x_test.append(img_arr)

x_val=[]

for folder in os.listdir(val_path):

    sub_path=val_path+folder

    for img in os.listdir(sub_path):

        image_path=sub_path+"/"+img

        ext = os.path.splitext(image_path)[-1].lower()

        if(ext == ".jpg" or ext == ".jpeg"):

            img_arr=cv2.imread(image_path)

            img_arr=cv2.resize(img_arr,(224,224))

            x_val.append(img_arr)

train_x=np.array(x_train)
test_x=np.array(x_test)
val_x=np.array(x_val)

train_x=train_x/255.0
test_x=test_x/255.0
val_x=val_x/255.0

#RESCALING IMAGE
train_datagen = ImageDataGenerator(rescale = 1./255)
test_datagen = ImageDataGenerator(rescale = 1./255)
val_datagen = ImageDataGenerator(rescale = 1./255)

train_generator = train_datagen.flow_from_directory(
        train_path, 
        target_size= (224,224),
        batch_size = batch_size,
        color_mode= "rgb",
        class_mode= "categorical")

test_generator = test_datagen.flow_from_directory(
        test_path, 
        target_size= (224,224),
        batch_size = batch_size,
        color_mode= "rgb",
        class_mode= "categorical")

val_generator = val_datagen.flow_from_directory(
        val_path, 
        target_size= (224,224),
        batch_size = batch_size,
        color_mode= "rgb",
        class_mode= "categorical")

train_y=train_generator.classes
test_y=test_generator.classes
val_y=val_generator.classes
train_generator.class_indices

"""#TRAINING PROCESS"""

from tensorflow.keras.callbacks import EarlyStopping
early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5)
#Early stopping to avoid overfitting of model

# fit the model
history = model.fit(
  train_x,
  train_y,
  validation_data=(val_x,val_y),
  batch_size=batch_size,
  callbacks=[early_stop],
  epochs=35,shuffle=True)

# loss
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.legend()
plt.show()

model.evaluate(test_x,test_y,batch_size=batch_size)

from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
import numpy as np

#predict
y_pred=model.predict(test_x)
y_pred=np.argmax(y_pred,axis=1)

#get classification report
print(classification_report(y_pred,test_y))

#get confusion matrix
print(confusion_matrix(y_pred,test_y))

model.save('fishClassModel9')

"""#TESTING WITH IMAGE FROM TEST"""

from PIL import Image

for im in os.listdir(IMAGE_DIR+"test/"):
    for im2 in os.listdir(IMAGE_DIR+"test/"+im):
        img = Image.open(IMAGE_DIR+"test/"+im+"/"+im2)
        img = img.resize((255,255))
        plt.imshow(img)
        plt.show()
        x=np.array(img)
        x=np.expand_dims(x,axis=0)
        images=np.vstack([x])
        pred=model.predict(images/255, batch_size=batch_size, verbose=1) 
        print("Path :"+im)
        if pred[0][0] > 0.6:
            print("{:.2f}".format(pred[0][0]))
            print("pseudanthias_lori")
        elif pred[0][1] > 0.6:
            print("{:.2f}".format(pred[0][1]))
            print("pseudanthias_randalli")
        elif pred[0][2] > 0.6:
            print("{:.2f}".format(pred[0][2]))
            print("pseudanthias_smithvanizi")
        else:
            print("Unknown")

"""#LOAD MODEL TEST"""

import tensorflow as tf
from PIL import Image
model = tf.keras.models.load_model('fishClassModel9')
batch_size = 256

for im in os.listdir(IMAGE_DIR+"test/"):
    for im2 in os.listdir(IMAGE_DIR+"test/"+im):
        img = Image.open(IMAGE_DIR+"test/"+im+"/"+im2)
        img = img.resize((224,224))
        plt.imshow(img)
        plt.show()
        x=np.array(img)
        x=np.expand_dims(x,axis=0)
        images=np.vstack([x])
        pred=model.predict(images/255, batch_size=batch_size, verbose=1) 
        print("Path :"+im)
        if pred[0][0] > 0.68:
            print("{:.2f}".format(pred[0][0]))
            print("pseudanthias_lori")
        elif pred[0][1] > 0.68:
            print("{:.2f}".format(pred[0][1]))
            print("pseudanthias_randalli")
        elif pred[0][2] > 0.68:
            print("{:.2f}".format(pred[0][2]))
            print("pseudanthias_smithvanizi")
        else:
            print("Unknown")

"""#TESTING FROM RANDOM IMAGE UPLOAD"""

import shutil
from google.colab import files
uploaded = files.upload()
filename = next(iter(uploaded))
print(filename)

shutil.move(filename, "randomTest/"+filename)

import tensorflow as tf
from PIL import Image
model = tf.keras.models.load_model('fishClassModel9')
batch_size = 256

for im in os.listdir("randomTest/"):
      img = Image.open("randomTest/"+im)
      img = img.resize((224,224))
      plt.imshow(img)
      plt.show()
      x=np.array(img)
      x=np.expand_dims(x,axis=0)
      images=np.vstack([x])
      pred=model.predict(images/255, batch_size=batch_size, verbose=1) 
      print("Path :"+im)
      if pred[0][0] > 0.9:
          print("{:.2f}".format(pred[0][0]))
          print("pseudanthias_lori")
      elif pred[0][1] > 0.9:
          print("{:.2f}".format(pred[0][1]))
          print("pseudanthias_randalli")
      elif pred[0][2] > 0.9:
          print("{:.2f}".format(pred[0][2]))
          print("pseudanthias_smithvanizi")
      else:
          print("Unknown")

